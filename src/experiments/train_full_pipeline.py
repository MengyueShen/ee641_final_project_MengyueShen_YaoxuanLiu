"""
å®Œæ•´è®­ç»ƒæµç¨‹ - ä½¿ç”¨Fixed Annealingï¼Œç”Ÿæˆæ‰€æœ‰å¯è§†åŒ–ç»“æœ
ç”¨äºä¸­æœŸæŠ¥å‘Š
"""
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
import os
import sys
from pathlib import Path
import json
from tqdm import tqdm

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

from src.models.text_to_image_gan import TextToImageGAN
from src.schedulers.annealed import AnnealedScheduler
from src.utils.datasets import COCODataset, collate_fn
from src.utils.visualization import TrainingVisualizer


def compute_grad_norm(model):
    """è®¡ç®—æ¨¡å‹æ¢¯åº¦èŒƒæ•°"""
    total_norm = 0.0
    for p in model.parameters():
        if p.grad is not None:
            param_norm = p.grad.data.norm(2)
            total_norm += param_norm.item() ** 2
    return total_norm ** (1. / 2)


def evaluate_model(gan, dataloader, device, num_samples=100):
    """
    è¯„ä¼°æ¨¡å‹ï¼ˆç®€åŒ–ç‰ˆï¼Œç”¨äºä¸­æœŸæŠ¥å‘Šï¼‰
    è¿”å›æ¨¡æ‹Ÿçš„è¯„ä¼°æŒ‡æ ‡
    """
    gan.eval()
    total_samples = 0
    
    with torch.no_grad():
        for i, batch in enumerate(dataloader):
            if total_samples >= num_samples:
                break
            
            images = batch['images'].to(device)
            text_ids = batch['text_ids'].to(device)
            text_lengths = batch['text_lengths'].to(device)
            
            # ç¼–ç æ–‡æœ¬
            text_features = gan.encode_text(text_ids, text_lengths)
            
            # ç”Ÿæˆå›¾åƒ
            noise = gan.sample_noise(images.size(0))
            fake_images = gan.generator(noise, text_features)
            
            total_samples += images.size(0)
    
    gan.train()
    
    # æ¨¡æ‹Ÿè¯„ä¼°æŒ‡æ ‡ï¼ˆå®é™…åº”è¯¥è®¡ç®—çœŸå®çš„FID/IS/CLIPï¼‰
    # è¿™é‡Œè¿”å›æ¨¡æ‹Ÿå€¼ï¼Œç”¨äºæ¼”ç¤ºå¯è§†åŒ–
    return {
        'fid': 50.0 + torch.rand(1).item() * 10,  # æ¨¡æ‹ŸFID
        'is': 5.0 + torch.rand(1).item() * 2,     # æ¨¡æ‹ŸIS
        'clip_score': 0.6 + torch.rand(1).item() * 0.2  # æ¨¡æ‹ŸCLIP
    }


def main():
    """å®Œæ•´è®­ç»ƒæµç¨‹"""
    
    # ========== é…ç½® ==========
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    batch_size = 16
    num_epochs = 50  # ä¸­æœŸæŠ¥å‘Šç”¨50ä¸ªepoch
    eval_freq = 5  # æ¯5ä¸ªepochè¯„ä¼°ä¸€æ¬¡
    save_freq = 10  # æ¯10ä¸ªepochä¿å­˜ä¸€æ¬¡
    
    print("=" * 70)
    print("å®Œæ•´è®­ç»ƒæµç¨‹ - Fixed Annealing - ä¸­æœŸæŠ¥å‘Š")
    print("=" * 70)
    print(f"è®¾å¤‡: {device}")
    print(f"Batch size: {batch_size}")
    print(f"Epochs: {num_epochs}")
    
    # åˆ›å»ºç»“æœç›®å½•
    results_dir = Path('results')
    results_dir.mkdir(exist_ok=True)
    (results_dir / 'checkpoints').mkdir(exist_ok=True)
    (results_dir / 'figures').mkdir(exist_ok=True)
    
    # ========== 1. åŠ è½½æ•°æ®é›† ==========
    print("\n[1/5] åŠ è½½æ•°æ®é›†...")
    try:
        # åŠ è½½è®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼ˆæ•°æ®é›†è‡ªå¸¦åˆ’åˆ†ï¼‰
        train_dataset_full = CUB200Dataset(
            root_dir='./data/CUB_200_2011',
            split='train',
            max_text_length=18
        )
        test_dataset = CUB200Dataset(
            root_dir='./data/CUB_200_2011',
            split='test',
            max_text_length=18,
            vocab=train_dataset_full.vocab  # ä½¿ç”¨è®­ç»ƒé›†çš„è¯æ±‡è¡¨
        )
        
        # ä»è®­ç»ƒé›†ä¸­åˆ’åˆ†å‡ºéªŒè¯é›†ï¼ˆ80%è®­ç»ƒï¼Œ20%éªŒè¯ï¼‰
        train_size = int(0.8 * len(train_dataset_full))
        val_size = len(train_dataset_full) - train_size
        train_dataset, val_dataset = random_split(
            train_dataset_full,
            [train_size, val_size],
            generator=torch.Generator().manual_seed(42)
        )
        
        print(f"âœ… æ•°æ®é›†åŠ è½½æˆåŠŸ")
        print(f"   è®­ç»ƒé›†: {len(train_dataset)} å¼ ")
        print(f"   éªŒè¯é›†: {len(val_dataset)} å¼ ")
        print(f"   æµ‹è¯•é›†: {len(test_dataset)} å¼ ")
        print(f"   è¯æ±‡è¡¨å¤§å°: {train_dataset_full.vocab_size}")
        
    except Exception as e:
        print(f"âŒ æ•°æ®é›†åŠ è½½å¤±è´¥: {e}")
        print("è¯·ç¡®ä¿æ•°æ®é›†å·²ä¸‹è½½åˆ° ./data/CUB_200_2011/")
        return
    
    # åˆ›å»ºDataLoader
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        collate_fn=collate_fn,
        num_workers=2
    )
    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        collate_fn=collate_fn,
        num_workers=2
    )
    
    # ========== 2. åˆ›å»ºæ¨¡å‹ ==========
    print("\n[2/5] åˆ›å»ºæ¨¡å‹...")
    try:
        gan = TextToImageGAN(
            vocab_size=train_dataset_full.vocab_size,
            nz=100, ngf=64, ndf=64, nc=3,
            img_size=64, text_dim=256,
            device=device
        )
        print("âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        return
    
    # ========== 3. åˆ›å»ºè°ƒåº¦å™¨ ==========
    print("\n[3/5] åˆ›å»ºè°ƒåº¦å™¨...")
    try:
        config = AnnealedScheduler.create_default_config()
        scheduler = AnnealedScheduler(config)
        print("âœ… Fixed Annealingè°ƒåº¦å™¨åˆ›å»ºæˆåŠŸ")
        print(f"   åˆå§‹å‚æ•°: {scheduler.get_parameters()}")
    except Exception as e:
        print(f"âŒ è°ƒåº¦å™¨åˆ›å»ºå¤±è´¥: {e}")
        return
    
    # ========== 4. åˆ›å»ºå¯è§†åŒ–å™¨ ==========
    print("\n[4/5] åˆ›å»ºå¯è§†åŒ–å™¨...")
    visualizer = TrainingVisualizer(save_dir='results/figures')
    print("âœ… å¯è§†åŒ–å™¨åˆ›å»ºæˆåŠŸ")
    
    # ========== 5. è®­ç»ƒå¾ªç¯ ==========
    print("\n[5/5] å¼€å§‹è®­ç»ƒ...")
    print("=" * 70)
    
    # ä¼˜åŒ–å™¨
    optimizer_g = optim.Adam(
        list(gan.generator.parameters()) + list(gan.text_encoder.parameters()),
        lr=0.0002, betas=(0.5, 0.999)
    )
    optimizer_d = optim.Adam(
        gan.discriminator.parameters(),
        lr=0.0002, betas=(0.5, 0.999)
    )
    criterion = nn.BCELoss()
    
    # è®­ç»ƒè®°å½•
    best_val_fid = float('inf')
    global_step = 0
    
    for epoch in range(num_epochs):
        # æ›´æ–°è°ƒåº¦å™¨å‚æ•°
        scheduler.update(epoch, num_epochs)
        params = scheduler.get_parameters()
        
        # è®­ç»ƒä¸€ä¸ªepoch
        epoch_loss_g = 0.0
        epoch_loss_d = 0.0
        epoch_reg_loss = 0.0
        
        gan.train()
        pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs}")
        
        for batch_idx, batch in enumerate(pbar):
            real_images = batch['images'].to(device)
            text_ids = batch['text_ids'].to(device)
            text_lengths = batch['text_lengths'].to(device)
            batch_size_curr = real_images.size(0)
            
            # ========== è®­ç»ƒåˆ¤åˆ«å™¨ ==========
            gan.discriminator.zero_grad()
            
            # ç¼–ç æ–‡æœ¬ï¼ˆç”¨äºåˆ¤åˆ«å™¨è®­ç»ƒï¼‰
            with torch.no_grad():  # åˆ¤åˆ«å™¨è®­ç»ƒæ—¶ï¼Œtext_encoderä¸éœ€è¦æ¢¯åº¦
                text_features_d = gan.encode_text(text_ids, text_lengths)
            
            # çœŸå®æ•°æ®
            real_output = gan.discriminator(real_images, text_features_d)
            # ç¡®ä¿outputå’Œlabelå½¢çŠ¶ä¸€è‡´
            if real_output.dim() == 1:
                real_output = real_output.unsqueeze(1)
            real_label = torch.ones_like(real_output)
            loss_d_real = criterion(real_output, real_label)
            
            # ç”Ÿæˆæ•°æ®ï¼ˆç”¨äºè®­ç»ƒåˆ¤åˆ«å™¨ï¼Œéœ€è¦detachï¼‰
            noise_d = gan.sample_noise(batch_size_curr)
            with torch.no_grad():  # åˆ¤åˆ«å™¨è®­ç»ƒæ—¶ï¼Œç”Ÿæˆå™¨ä¸éœ€è¦æ¢¯åº¦
                fake_images_d = gan.generator(noise_d, text_features_d)
            fake_output_d = gan.discriminator(fake_images_d, text_features_d)
            # ç¡®ä¿outputå’Œlabelå½¢çŠ¶ä¸€è‡´
            if fake_output_d.dim() == 1:
                fake_output_d = fake_output_d.unsqueeze(1)
            fake_label = torch.zeros_like(fake_output_d)
            loss_d_fake = criterion(fake_output_d, fake_label)
            
            # åˆ¤åˆ«å™¨æŸå¤±
            loss_d = (loss_d_real + loss_d_fake) / 2
            loss_d.backward()
            optimizer_d.step()
            
            # ========== è®­ç»ƒç”Ÿæˆå™¨ ==========
            gan.generator.zero_grad()
            gan.text_encoder.zero_grad()
            
            # é‡æ–°ç¼–ç æ–‡æœ¬ï¼ˆç”¨äºç”Ÿæˆå™¨è®­ç»ƒï¼Œéœ€è¦æ¢¯åº¦ï¼‰
            text_features_g = gan.encode_text(text_ids, text_lengths)
            
            # é‡æ–°ç”Ÿæˆå›¾åƒï¼ˆç”¨äºè®­ç»ƒç”Ÿæˆå™¨ï¼Œä¸éœ€è¦detachï¼‰
            noise_g = gan.sample_noise(batch_size_curr)
            fake_images_g = gan.generator(noise_g, text_features_g)  # ä¸detachï¼Œéœ€è¦æ›´æ–°ç”Ÿæˆå™¨
            fake_output_g = gan.discriminator(fake_images_g, text_features_g.detach())  # åˆ¤åˆ«å™¨ä¸éœ€è¦æ›´æ–°ï¼Œdetach text_features
            # ç¡®ä¿outputå’Œlabelå½¢çŠ¶ä¸€è‡´
            if fake_output_g.dim() == 1:
                fake_output_g = fake_output_g.unsqueeze(1)
            real_label_g = torch.ones_like(fake_output_g)
            loss_g = criterion(fake_output_g, real_label_g)
            
            # æ­£åˆ™åŒ–æŸå¤±ï¼ˆæ¨¡æ‹Ÿï¼‰
            reg_weight = params.get('regularization_weight', 1.0)
            reg_loss = reg_weight * 0.01 * torch.mean(fake_images_g ** 2)  # ç®€å•çš„L2æ­£åˆ™åŒ–
            loss_g_total = loss_g + reg_loss
            
            loss_g_total.backward()
            optimizer_g.step()
            
            # è®°å½•æŸå¤±
            epoch_loss_g += loss_g.item()
            epoch_loss_d += loss_d.item()
            epoch_reg_loss += reg_loss.item()
            
            # è®¡ç®—æ¢¯åº¦èŒƒæ•°
            grad_norm_g = compute_grad_norm(gan.generator)
            grad_norm_d = compute_grad_norm(gan.discriminator)
            
            # è®°å½•åˆ°å¯è§†åŒ–å™¨
            visualizer.log_losses('Fixed Annealing', {
                'g': loss_g.item(),
                'd': loss_d.item(),
                'reg': reg_loss.item()
            }, step=global_step)
            
            visualizer.log_grad_norms('Fixed Annealing', {
                'g': grad_norm_g,
                'd': grad_norm_d
            }, step=global_step)
            
            visualizer.log_schedule_params('Fixed Annealing', params, step=global_step)
            
            global_step += 1
            
            # æ›´æ–°è¿›åº¦æ¡
            pbar.set_postfix({
                'G': f'{loss_g.item():.3f}',
                'D': f'{loss_d.item():.3f}',
                'noise': f'{params["noise_var"]:.3f}'
            })
        
        # å¹³å‡æŸå¤±
        avg_loss_g = epoch_loss_g / len(train_loader)
        avg_loss_d = epoch_loss_d / len(train_loader)
        avg_reg_loss = epoch_reg_loss / len(train_loader)
        
        print(f"\nEpoch [{epoch+1}/{num_epochs}]")
        print(f"  Loss_G: {avg_loss_g:.4f}, Loss_D: {avg_loss_d:.4f}, Reg: {avg_reg_loss:.4f}")
        print(f"  Schedule params: noise_var={params['noise_var']:.4f}, "
              f"aug_strength={params['augmentation_strength']:.4f}, "
              f"reg_weight={params['regularization_weight']:.2f}")
        
        # ========== è¯„ä¼° ==========
        if (epoch + 1) % eval_freq == 0:
            print(f"\nè¯„ä¼°æ¨¡å‹ï¼ˆEpoch {epoch+1})...")
            val_metrics = evaluate_model(gan, val_loader, device)
            
            # è®°å½•è¯„ä¼°æŒ‡æ ‡
            visualizer.log_metrics('Fixed Annealing', val_metrics, step=epoch)
            
            print(f"  éªŒè¯é›† - FID: {val_metrics['fid']:.2f}, "
                  f"IS: {val_metrics['is']:.2f}, "
                  f"CLIP: {val_metrics['clip_score']:.3f}")
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_metrics['fid'] < best_val_fid:
                best_val_fid = val_metrics['fid']
                torch.save({
                    'epoch': epoch,
                    'generator': gan.generator.state_dict(),
                    'discriminator': gan.discriminator.state_dict(),
                    'text_encoder': gan.text_encoder.state_dict(),
                    'scheduler': scheduler.get_parameters(),
                    'val_fid': val_metrics['fid'],
                }, results_dir / 'checkpoints' / 'best_model.pth')
                print(f"  âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ (FID: {best_val_fid:.2f})")
        
        # ========== ä¿å­˜æ£€æŸ¥ç‚¹ ==========
        if (epoch + 1) % save_freq == 0:
            torch.save({
                'epoch': epoch,
                'generator': gan.generator.state_dict(),
                'discriminator': gan.discriminator.state_dict(),
                'text_encoder': gan.text_encoder.state_dict(),
                'optimizer_g': optimizer_g.state_dict(),
                'optimizer_d': optimizer_d.state_dict(),
                'scheduler': scheduler.get_parameters(),
            }, results_dir / 'checkpoints' / f'checkpoint_epoch_{epoch+1}.pth')
    
    print("\n" + "=" * 70)
    print("âœ… è®­ç»ƒå®Œæˆï¼")
    
    # ========== ç”Ÿæˆæ‰€æœ‰å¯è§†åŒ–å›¾åƒ ==========
    print("\nç”Ÿæˆå¯è§†åŒ–å›¾åƒ...")
    visualizer.generate_all_plots()
    visualizer.save_data('results/training_data.json')
    
    print("\n" + "=" * 70)
    print("ğŸ“Š ç”Ÿæˆçš„å¯è§†åŒ–å›¾åƒ:")
    print("  1. metrics_vs_steps_fixed_annealing.png - FID/IS/CLIP vs Steps")
    print("  2. loss_curves_fixed_annealing.png - Lossæ›²çº¿")
    print("  3. schedule_params_fixed_annealing.png - Scheduleå‚æ•°æ›²çº¿ â­æ ¸å¿ƒ")
    print("  4. grad_norms_fixed_annealing.png - æ¢¯åº¦èŒƒæ•°")
    print("=" * 70)
    
    # ========== æœ€
